---
title: "Machine learning and job matching"
author: "Neil Rankin"
date: "August 21, 2017"
output: beamer_presentation
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(ggplot2)
library(stargazer)
```

## Goal

- Can we build a 'machine learning' algorithm to identify young people who are likely to become employed in South Africa?


## Outline

- What is machine learning (ML)?

- Can we apply this in a South African labour market environment?

- Building a prototype ML algorithm


## What is machine learning (ML)?

'Machine learning is the subfield of computer science that, according to Arthur Samuel, gives "computers the ability to learn without being explicitly programmed"... Evolved from the study of pattern recognition and computational learning theory in artificial intelligence, machine learning explores the study and construction of algorithms that can learn from and make predictions on data â€“ such algorithms overcome following strictly static program instructions by making data-driven predictions or decisions, through building a model from sample inputs. Machine learning is employed in a range of computing tasks where designing and programming explicit algorithms with good performance is difficult or infeasible; example applications include email filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), learning to rank, and computer vision.'

[Wikipedia](https://en.wikipedia.org/wiki/Machine_learning)

## Applying this in a South African labour market environment

**[Harambee Youth Employment Accelerator](http://harambee.co.za/harambee/)** is an organisation which brings together young people, who are marginalised in the labour market, and employers looking for entry-level recruits.

Their reputation depends on finding good, but overlooked, candidates. They need a mechanism to find these candidates? Can we help?


## The Harambee process

1. 'Source' people either through actively recruiting or through sign-ups trhough a mobile site
2. Invite people to further assessments and support:

    + 'Work-seeker support' which includes interview preparation, help with job search etc
    + 'Learning Potential' or CFT. A non-verbal reasoning test.
    + Communications and numeracy tests (not all candidates get this, and these can vary between candidates)
3. 'Bridge' with job-specific skills
4. Facilitate placement (for those going through the whole process), or self-placement (who find a job after work-seeker support)
5. 'Employment Journey' survey every 4 months after initial contact

Can we find characteristics which can help to pick candidates to go through this process?

## Building a prototype ML algorithm (for employment)

Steps: 
 
 1. Split the dataset between training and testing
 2. Train a model on the training data
    + OLS
    + Logit (?)
    + Random forest (?)
 3. Evaluate it on the test data
 
See the do file, R script
 

## ML algorithm, step 1

Split the data into a training and testing dataset
 
1. Set the random number seed
2. Generate a random number
3. Split into training and testing

## ML algorithm, step 1 (STATA)

`set seed 12345` 

`ssc install randomtag` 

`randomtag` 

## ML algorithm, step 1 (R)


```{r load_data}

ej_data <- readRDS("data/ej_data.rds")

ej_data$employed <- ifelse(ej_data$working=="Yes", TRUE,
                           ifelse(ej_data$working=="No", FALSE, NA))


```

```{r split_training_test, echo=TRUE}
### split out training and test data
set.seed(1234)
## Using 70% as training currently

# check dimensions of data
dim(ej_data) 

#Sample Indexes
indexes = sample(1:nrow(ej_data), size=0.3*nrow(ej_data))

# Split data and just checking dimensions
ej_test = ej_data[indexes,]
dim(ej_test)

ej_train = ej_data[-indexes,]
dim(ej_train)

#look at proportions of yellow jobs
table(ej_data$employed)
table(ej_train$employed)
table(ej_test$employed)
```


## Training the model

```{r training_OLS, results='asis', warning=FALSE, message=FALSE, resize.height=0.5,resize.width=0.5}
#Need stargazer here

model1.1 <- lm(employed ~ english_mark + as.numeric(CFT_answer_ODS), ej_train)

stargazer(model1.1, header = FALSE)


```

## Testing the model (and a picture)

```{r test_OLS, warning=FALSE}
ej_test$predicted_model1.1 <- predict(model1.1, newdata = ej_test)

ggplot(ej_test, aes(x=predicted_model1.1, fill=employed)) + geom_density(position = "identity", alpha=0.4) + scale_fill_manual(values=c("dark green", "yellow"))

```

## Improve the model?

Can you improve the predictive ability of the model?
